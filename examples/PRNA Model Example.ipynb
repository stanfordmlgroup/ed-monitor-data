{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14b15e29",
   "metadata": {},
   "source": [
    "# PRNA Model Example\n",
    "\n",
    "This notebook demonstrates how to use pre-trained Transformer models based on the PRNA architecture described in [this paper](https://www.physionet.org/files/challenge-2020/1.0.1/papers/CinC2020-107.pdf).\n",
    "\n",
    "A full list of pre-trained models are available at [this location](https://github.com/stanfordmlgroup/aihc-win21-ed-monitor/blob/main/MODELS.md). Please contact tomjin \\[at\\] stanford.edu for access.\n",
    "\n",
    "Prior to running this notebook, you will need to install the `edm` module by following the README.md on the homepage of this repository.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bd99d2",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f1f88a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from edm.models.transformer_model import load_best_model\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bafc054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output classes that the PRNA model was trained against\n",
    "\n",
    "classes = sorted(['270492004', '164889003', '164890007', '426627000', '713427006',\n",
    "                  '713426002', '445118002', '39732003', '164909002', '251146004',\n",
    "                  '698252002', '10370003', '284470004', '427172004', '164947007',\n",
    "                  '111975006', '164917005', '47665007', '427393009',\n",
    "                  '426177001', '426783006', '427084000', '164934002',\n",
    "                  '59931005'])\n",
    "\n",
    "concept_to_desc = {\n",
    "    \"270492004\": \"first degree atrioventricular block\",\n",
    "    \"164889003\": \"atrial fibrillation\",\n",
    "    \"426627000\": \"bradycardia\",\n",
    "    \"164890007\": \"atrial flutter\",\n",
    "    \"713427006\": \"complete right bundle branch block\",\n",
    "    \"713426002\": \"incomplete right bundle branch block\",\n",
    "    \"445118002\": \"left anterior fascicular block\",\n",
    "    \"39732003\": \"left axis deviation\",\n",
    "    \"164909002\": \"left bundle branch block\",\n",
    "    \"251146004\": \"low QRS voltage\",\n",
    "    \"698252002\": \"non-specific intraventricular conduction delay\",\n",
    "    \"10370003\": \"Pacing rhythm\",\n",
    "    \"284470004\": \"Premature atrial contraction\",\n",
    "    \"427172004\": \"Premature ventricular contractions\",\n",
    "    \"164947007\": \"Prolonged PR interval\",\n",
    "    \"111975006\": \"Prolonged QT interval\",\n",
    "    \"164917005\": \"Q wave abnormal\",\n",
    "    \"47665007\": \"Right axis deviation\",\n",
    "    \"427393009\": \"Sinus arrhythmia\",\n",
    "    \"426177001\": \"Sinus bradycardia\",\n",
    "    \"426783006\": \"Sinus rhythm\",\n",
    "    \"427084000\": \"Sinus tachycardia\",\n",
    "    \"164934002\": \"T wave abnormal\",\n",
    "    \"59931005\": \"T wave inversion\",\n",
    "    \"59118001\": \"Right bundle branch block (disorder)\",\n",
    "    \"63593006\": \"Supraventricular premature beats\",\n",
    "    \"17338001\": \"Ventricular premature beats\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13ceec2",
   "metadata": {},
   "source": [
    "## Cardiac Abnormality Class Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa03091",
   "metadata": {},
   "source": [
    "### Load Model\n",
    "\n",
    "- `embedding_size` controls the size of the fully-connected layers. Refer to the pre-trained model chart.\n",
    "- `remove_last_layer` controls whether the last layer should be removed. If not removed, we are predicting the cardiac abnormality class.\n",
    "- `model_path` specifies where the pre-trained models are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df2f780a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepfeat_sz=64, nb_patient_feats=0\n",
      "Loading best model: best_loss 0.10535395583685707 best_auroc tensor(0.8580) at epoch 31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): CTN(\n",
       "    (encoder): Sequential(\n",
       "      (0): Conv1d(1, 128, kernel_size=(14,), stride=(3,), padding=(2,), bias=False)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv1d(128, 256, kernel_size=(14,), stride=(3,), bias=False)\n",
       "      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Conv1d(256, 256, kernel_size=(10,), stride=(2,), bias=False)\n",
       "      (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): Conv1d(256, 256, kernel_size=(10,), stride=(2,), bias=False)\n",
       "      (10): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv1d(256, 256, kernel_size=(10,), stride=(1,), bias=False)\n",
       "      (13): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (14): ReLU(inplace=True)\n",
       "      (15): Conv1d(256, 256, kernel_size=(10,), stride=(1,), bias=False)\n",
       "      (16): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (17): ReLU(inplace=True)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (pe): PositionalEncoding(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (transformer_encoder): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (3): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (4): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (5): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (6): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (7): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (fc2): Linear(in_features=64, out_features=24, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_size = 64\n",
    "remove_last_layer = False\n",
    "model_path = \"/deep/group/ed-monitor/models/prna/outputs-wide-64-15sec-bs64/saved_models/ctn/fold_1/ctn.tar\"\n",
    "\n",
    "model = load_best_model(model_path, deepfeat_sz=embedding_size, remove_last_layer=remove_last_layer)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02912a4a",
   "metadata": {},
   "source": [
    "### Run Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a565f9c",
   "metadata": {},
   "source": [
    "Create examples input of shape `(num_samples, num_channels, ecg_length)`\n",
    "\n",
    "- `num_samples`: Size of your mini-batch\n",
    "- `num_channels`: Number of ECG channels. Most PRNA models were trained using a single channel, so this would be fixed to `1`\n",
    "- `ecg_length`: Length of the ECG waveform. e.g. if 15 sec ECG at 500 Hz => length would be 7500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11a54c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of input torch.Size([1, 1, 7500])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.zeros((1, 1, 7500))\n",
    "print(f\"Size of input {input_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19883527",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Run model inference and print the probability of each output class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1e7fc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of output 1\n",
      "---\n",
      "   Pacing rhythm: feature strength = 6.5e-05\n",
      "   Prolonged QT interval: feature strength = 8.4e-05\n",
      "   atrial fibrillation: feature strength = 0.044777\n",
      "   atrial flutter: feature strength = 0.002004\n",
      "   left bundle branch block: feature strength = 0.007083\n",
      "   Q wave abnormal: feature strength = 7.5e-05\n",
      "   T wave abnormal: feature strength = 0.000572\n",
      "   Prolonged PR interval: feature strength = 0.0\n",
      "   low QRS voltage: feature strength = 0.000371\n",
      "   first degree atrioventricular block: feature strength = 0.007279\n",
      "   Premature atrial contraction: feature strength = 0.046835\n",
      "   left axis deviation: feature strength = 3.5e-05\n",
      "   Sinus bradycardia: feature strength = 0.000714\n",
      "   bradycardia: feature strength = 0.010025\n",
      "   Sinus rhythm: feature strength = 0.030146\n",
      "   Sinus tachycardia: feature strength = 0.021804\n",
      "   Premature ventricular contractions: feature strength = 0.017828\n",
      "   Sinus arrhythmia: feature strength = 0.000154\n",
      "   left anterior fascicular block: feature strength = 0.0\n",
      "   Right axis deviation: feature strength = 0.000164\n",
      "   T wave inversion: feature strength = 0.000901\n",
      "   non-specific intraventricular conduction delay: feature strength = 0.00047\n",
      "   incomplete right bundle branch block: feature strength = 0.001486\n",
      "   complete right bundle branch block: feature strength = 0.032547\n"
     ]
    }
   ],
   "source": [
    "probs = model(input_tensor, None).sigmoid().cpu().detach().numpy().tolist()\n",
    "\n",
    "print(f\"Length of output {len(probs)}\")\n",
    "print(\"---\")\n",
    "\n",
    "# Get the first sample and enumerate each output feature\n",
    "probs = probs[0]\n",
    "for i, prob in enumerate(probs):\n",
    "    concept = classes[i]\n",
    "    desc = concept_to_desc[concept]\n",
    "    print(f\"   {desc}: feature strength = {round(prob, 6)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec5ee6d",
   "metadata": {},
   "source": [
    "## ECG Embeddings\n",
    "\n",
    "This is identical to the cardiac abnormality class prediction (i.e. uses the same model), except we remove the last fully-connected layer of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaa6cb8",
   "metadata": {},
   "source": [
    "### Load Model\n",
    "\n",
    "- `embedding_size` controls the size of the fully-connected layers and hence output embeddings. Refer to the pre-trained model chart.\n",
    "- `remove_last_layer` controls whether the last layer should be removed. If removed, we are outputting the embeddings instead of the cardiac abnormality class.\n",
    "- `model_path` specifies where the pre-trained models are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d1ea38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepfeat_sz=64, nb_patient_feats=0\n",
      "Loading best model: best_loss 0.10535395583685707 best_auroc tensor(0.8580) at epoch 31\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv1d(1, 128, kernel_size=(14,), stride=(3,), padding=(2,), bias=False)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv1d(128, 256, kernel_size=(14,), stride=(3,), bias=False)\n",
       "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv1d(256, 256, kernel_size=(10,), stride=(2,), bias=False)\n",
       "    (7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): Conv1d(256, 256, kernel_size=(10,), stride=(2,), bias=False)\n",
       "    (10): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv1d(256, 256, kernel_size=(10,), stride=(1,), bias=False)\n",
       "    (13): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): Conv1d(256, 256, kernel_size=(10,), stride=(1,), bias=False)\n",
       "    (16): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU(inplace=True)\n",
       "  )\n",
       "  (1): Transformer(\n",
       "    (pe): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (6): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (7): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): Linear(in_features=256, out_features=64, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_size = 64\n",
    "remove_last_layer = True\n",
    "model_path = \"/deep/group/ed-monitor/models/prna/outputs-wide-64-15sec-bs64/saved_models/ctn/fold_1/ctn.tar\"\n",
    "\n",
    "model = load_best_model(model_path, deepfeat_sz=embedding_size, remove_last_layer=remove_last_layer)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac651f3f",
   "metadata": {},
   "source": [
    "### Run Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8772354",
   "metadata": {},
   "source": [
    "Create examples input of shape `(num_samples, num_channels, ecg_length)`\n",
    "\n",
    "- `num_samples`: Size of your mini-batch\n",
    "- `num_channels`: Number of ECG channels. Most PRNA models were trained using a single channel, so this would be fixed to `1`\n",
    "- `ecg_length`: Length of the ECG waveform. e.g. if 15 sec ECG at 500 Hz => length would be 7500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a4fc311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of input torch.Size([1, 1, 7500])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.zeros((1, 1, 7500))\n",
    "print(f\"Size of input {input_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11854516",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Run model inference and print the probability of each output class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0367114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of embedding 1\n",
      "---\n",
      "Embedding shape: (64,)\n",
      "Embedding: [0.07299398 0.15182257 0.01397314 0.17013563 0.3177759  0.69479364\n",
      " 0.83668965 0.09662822 0.3713273  0.77085304 0.4777339  0.85967314\n",
      " 0.8841248  0.45576975 0.5174365  0.21101093 0.29974195 0.98962945\n",
      " 0.7486474  0.16653965 0.686424   0.13565567 0.33195427 0.15843181\n",
      " 0.12933792 0.6975239  0.0405843  0.02273056 0.6107944  0.23825002\n",
      " 0.19473583 0.39380682 0.7354453  0.3443672  0.23817264 0.10366894\n",
      " 0.7796624  0.28014058 0.7583948  0.45048335 0.24592234 0.7468526\n",
      " 0.03179573 0.23923036 0.99203616 0.30388948 0.843778   0.6548131\n",
      " 0.82875854 0.92582357 0.09824307 0.37577543 0.16038077 0.03856083\n",
      " 0.9765047  0.4893258  0.09355064 0.3517185  0.69492686 0.1309337\n",
      " 0.9475582  0.49119705 0.72859776 0.17606543]\n"
     ]
    }
   ],
   "source": [
    "embedding = model(input_tensor).sigmoid().cpu().detach().numpy()\n",
    "\n",
    "print(f\"Length of embedding {len(embedding)}\")\n",
    "print(\"---\")\n",
    "print(f\"Embedding shape: {embedding[0].shape}\")\n",
    "print(f\"Embedding: {embedding[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7d9ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
